{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9fe81d-bf53-409b-b216-f7bae23c806d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join as pjoin\n",
    "\n",
    "import albumentations as A\n",
    "import numpy as np\n",
    "import torch\n",
    "from accelerate import Accelerator\n",
    "from matplotlib import pyplot as plt\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from checkpointer import CheckpointSaver, load_checkpoint\n",
    "from dataset import (\n",
    "    ID_LABELS_MAP,\n",
    "    CustomVOCDetectionDataset,\n",
    "    detection_collate_fn,\n",
    ")\n",
    "from loss import YOLOLoss\n",
    "from metric import CustomMeanAveragePrecision\n",
    "from train import train\n",
    "from utils import add_bboxes_on_img, non_max_suppression, seed_everything\n",
    "from yolo_custom import yolo_v8_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0e9342-17d1-4051-bee8-43b4cf3d8f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42, torch_deterministic=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7417bf-fad0-409b-831e-7ff59f3ef358",
   "metadata": {},
   "source": [
    "## Аугментации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb7bef5-65e7-4f43-bb17-b94729cbee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 640\n",
    "MOSAIC = True\n",
    "\n",
    "# YOLO bbox format: [x_center, y_center, width, height] (normalized)\n",
    "bbox_params = A.BboxParams(\n",
    "    format=\"yolo\", min_area=16, min_visibility=0.1, label_fields=[\"label_ids\"]\n",
    ")\n",
    "\n",
    "train_transforms = A.Compose(\n",
    "    [\n",
    "        # geometric transforms\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.Rotate(limit=10, p=0.5),\n",
    "        # spatial transforms\n",
    "        (\n",
    "            A.AtLeastOneBBoxRandomCrop(height=IMAGE_SIZE, width=IMAGE_SIZE, p=1.0)\n",
    "            if MOSAIC\n",
    "            else A.SmallestMaxSize(max_size=IMAGE_SIZE, p=1.0)\n",
    "        ),\n",
    "        # color transforms\n",
    "        A.OneOf(\n",
    "            [\n",
    "                A.RandomBrightnessContrast(\n",
    "                    brightness_limit=0.2, contrast_limit=0.2, p=0.5\n",
    "                ),\n",
    "                A.HueSaturationValue(\n",
    "                    hue_shift_limit=10,\n",
    "                    sat_shift_limit=20,\n",
    "                    val_shift_limit=10,\n",
    "                    p=0.5,\n",
    "                ),\n",
    "            ],\n",
    "            p=0.5,\n",
    "        ),\n",
    "        # conversion\n",
    "        A.ToTensorV2(),\n",
    "    ],\n",
    "    bbox_params=bbox_params,\n",
    ")\n",
    "\n",
    "val_transforms = A.Compose(\n",
    "    [\n",
    "        A.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "        A.ToTensorV2(),\n",
    "    ],\n",
    "    bbox_params=bbox_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e756dcf5-5913-4a40-a69f-15be09460f84",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb0ef48-fe8e-40d7-b2a5-77b04d4e0a5f",
   "metadata": {},
   "source": [
    "Набор данных Pascal VOC. Рассмотрим его версию для задачи сегментации. \n",
    "\n",
    "Сайт: http://host.robots.ox.ac.uk/pascal/VOC/\n",
    "\n",
    "Лидерборд за 2012 год: http://host.robots.ox.ac.uk:8080/leaderboard/displaylb_main.php?challengeid=11&compid=3\n",
    "\n",
    "При тех или иных проблемах со скачиванием с сайта соревнования, скачайте и распакуйте архив в папку `data` (`data/VOCdevkit`) отсюда: https://disk.yandex.ru/d/1jS3yBBN7YdZ-w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3b3283-cad7-42bf-9937-ffc93aefd0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomVOCDetectionDataset(\n",
    "    root=\"data\",\n",
    "    year=\"2012\",\n",
    "    image_set=\"train\",\n",
    "    download=False,  # True\n",
    "    transform=train_transforms,  # transform, not transforms!\n",
    "    mosaic=MOSAIC,\n",
    "    img_size=IMAGE_SIZE,\n",
    ")\n",
    "\n",
    "val_dataset = CustomVOCDetectionDataset(\n",
    "    root=\"data\",\n",
    "    year=\"2012\",\n",
    "    image_set=\"val\",\n",
    "    download=False,\n",
    "    transform=val_transforms,\n",
    "    mosaic=False,\n",
    "    img_size=IMAGE_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0890fd91-70f3-4780-812e-330e1f2b6e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "img, target = train_dataset[0]\n",
    "\n",
    "img = img.numpy().transpose(1, 2, 0).astype(np.uint8)\n",
    "\n",
    "img_bboxes = img.copy()\n",
    "for bbox, label_id in zip(target[\"bboxes\"], target[\"label_ids\"]):\n",
    "    label = ID_LABELS_MAP[label_id.item()]\n",
    "    img_bboxes = add_bboxes_on_img(\n",
    "        img=img_bboxes,\n",
    "        bbox=bbox,\n",
    "        bbox_format=\"xcycwh\",\n",
    "        denormalize_bbox=True,\n",
    "        label=label,\n",
    "    )\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(12, 24))\n",
    "ax[0].imshow(img)\n",
    "ax[1].imshow(img_bboxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d98159-01d8-4fcb-ac03-dac88d3a1fde",
   "metadata": {},
   "source": [
    "## Обучаем модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49d5c1a-0dfe-4f95-86f3-4f40ac05f651",
   "metadata": {},
   "source": [
    "См. `train.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd46025-c5b0-4b08-bb90-ea01e6909319",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES_NUM = 20\n",
    "\n",
    "LEARNING_RATE_SGD = 1e-2\n",
    "LEARNING_RATE_ADAM = 1e-4\n",
    "MIN_LEARNING_RATE = 1e-5\n",
    "WEIGHT_DECAY = 1e-5\n",
    "MOMENTUM_SGD = 0.93\n",
    "BETAS_ADAM = (0.9, 0.999)\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4\n",
    "GRAD_ACCUMULATION_STEPS = 1\n",
    "EPOCH_NUM = 100\n",
    "SCHEDULER_PATIENCE = 5\n",
    "SCHEDULER_GAMMA = 0.5\n",
    "CHECKPOINTS_DIR = \"checkpoints\"\n",
    "TENSORBOARD_DIR = \"tensorboard\"\n",
    "RM_CHECKPOINTS_DIR = False\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40ca035-e42f-44ec-a50b-af409551cd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=detection_collate_fn,\n",
    "    pin_memory=True,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    collate_fn=detection_collate_fn,\n",
    "    pin_memory=True,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "model = yolo_v8_n(classes_num=20)\n",
    "# model = load_checkpoint(\n",
    "#     model=model,\n",
    "#     load_path=pjoin(CHECKPOINTS_DIR, \"model_checkpoint_best.pt\"),\n",
    "# )\n",
    "\n",
    "metric_fn = CustomMeanAveragePrecision(box_format=\"cxcywh\", iou_type=\"bbox\")\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE_SGD,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    momentum=MOMENTUM_SGD,\n",
    "    nesterov=True,\n",
    ")\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer=optimizer,\n",
    "    mode=\"max\",\n",
    "    factor=SCHEDULER_GAMMA,\n",
    "    patience=SCHEDULER_PATIENCE,\n",
    "    min_lr=MIN_LEARNING_RATE,\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(\n",
    "    cpu=\"cpu\" == DEVICE,\n",
    "    mixed_precision=\"no\",\n",
    "    gradient_accumulation_steps=GRAD_ACCUMULATION_STEPS,\n",
    ")\n",
    "model, optimizer, train_dataloader, val_dataloader, lr_scheduler = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, val_dataloader, lr_scheduler\n",
    ")\n",
    "\n",
    "loss_fn = YOLOLoss(model=model)  # after accelerate!\n",
    "\n",
    "os.makedirs(CHECKPOINTS_DIR, exist_ok=True)\n",
    "checkpointer = CheckpointSaver(\n",
    "    accelerator=accelerator,\n",
    "    model=model,\n",
    "    metric_name=\"map\",\n",
    "    save_dir=CHECKPOINTS_DIR,\n",
    "    rm_save_dir=RM_CHECKPOINTS_DIR,\n",
    "    max_history=5,\n",
    "    should_minimize=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48155760-f7e8-4071-8129-52d078f6cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(TENSORBOARD_DIR, exist_ok=True)\n",
    "tensorboard_logger = torch.utils.tensorboard.SummaryWriter(log_dir=TENSORBOARD_DIR)\n",
    "\n",
    "# Раскомментировать в Google Colab\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir \"tensorboard\"  --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1071e9-690e-43c4-a8a9-9551171ba6a5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    metric_fn=metric_fn,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    accelerator=accelerator,\n",
    "    epoch_num=EPOCH_NUM,\n",
    "    checkpointer=checkpointer,\n",
    "    tb_logger=tensorboard_logger,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8e6f95-f557-4f78-a44d-f6f33a4dbeef",
   "metadata": {},
   "source": [
    "## Загрузим и протестируем обученную модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726e0672-c678-43fc-abad-21fe4bf058b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CHECKPOINTS_DIR = \"checkpoints\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = yolo_v8_n(classes_num=20)\n",
    "model = load_checkpoint(\n",
    "    model=model,\n",
    "    load_path=pjoin(CHECKPOINTS_DIR, \"model_checkpoint_best.pt\"),\n",
    ")\n",
    "model = model.to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8bc0de-933f-4e1b-b4cb-5a6d0b9f8ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 0\n",
    "img, target = val_dataset[sample_idx]\n",
    "\n",
    "outputs = model(img.unsqueeze(0).to(DEVICE))\n",
    "outputs = non_max_suppression(preds=outputs, conf_thd=0.3, iou_thd=0.5)\n",
    "outputs = outputs[0]\n",
    "\n",
    "img = img.numpy().transpose(1, 2, 0).astype(np.uint8)\n",
    "\n",
    "h, w = img.shape[:2]\n",
    "img_bboxes_pred = img.copy()\n",
    "for output in outputs:\n",
    "    bbox = output[:4].tolist()\n",
    "    conf = output[4].item()\n",
    "    label = ID_LABELS_MAP[output[5].item()]\n",
    "    img_bboxes_pred = add_bboxes_on_img(\n",
    "        img=img_bboxes_pred,\n",
    "        bbox=bbox,\n",
    "        bbox_format=\"xyxy\",\n",
    "        denormalize_bbox=False,\n",
    "        label=label,\n",
    "    )\n",
    "\n",
    "img_bboxes_target = img.copy()\n",
    "for bbox, label_id in zip(target[\"bboxes\"], target[\"label_ids\"]):\n",
    "    label = ID_LABELS_MAP[label_id.item()]\n",
    "    img_bboxes_target = add_bboxes_on_img(\n",
    "        img=img_bboxes_target,\n",
    "        bbox=bbox,\n",
    "        bbox_format=\"xcycwh\",\n",
    "        denormalize_bbox=True,\n",
    "        label=label,\n",
    "    )\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 24))\n",
    "ax[0].imshow(img)\n",
    "ax[1].imshow(img_bboxes_pred)\n",
    "ax[2].imshow(img_bboxes_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a86a3a-83a4-423c-a64d-7e3560d311a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
