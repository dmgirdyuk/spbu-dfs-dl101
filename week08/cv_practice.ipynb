{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cffdd5d6-3712-45d2-b5c0-cbb48b5f377d",
   "metadata": {},
   "source": [
    "# Обучение моделей в Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc18f6a-31c9-4ff1-b7a7-02a7a13f85cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from os.path import join as pjoin\n",
    "from shutil import rmtree\n",
    "\n",
    "import albumentations\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from accelerate import Accelerator\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets\n",
    "\n",
    "from checkpointer import CheckpointSaver, load_checkpoint\n",
    "from dataset import CustomVOCSegmentation\n",
    "from deeplabv3plus.modeling import deeplabv3_resnet50\n",
    "from loss import CEDiceLoss, CrossEntropyLoss, DiceLoss, FocalLoss\n",
    "from metric import IoUMetric\n",
    "from train import count_pytorch_model_params, train\n",
    "from unet import UNet\n",
    "from unet_custom import CustomUNet\n",
    "from utils import seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12069a41-bbcb-4292-931b-27c367515ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42, torch_deterministic=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d17238-f92d-4347-a84e-91b2f37598bc",
   "metadata": {},
   "source": [
    "## Аугментации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0959cf2-ad28-4ae5-84f9-02fd7beb6190",
   "metadata": {},
   "source": [
    "Трансформации/аугментации для исходных изображений и масок/таргетов.\n",
    "\n",
    "Аугментации для задач компьютерного хрения: https://albumentations.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662c1e5a-ca36-4b9f-802a-da8e3786c5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256\n",
    "train_transforms = albumentations.Compose(\n",
    "    [\n",
    "        # albumentations.SmallestMaxSize(max_size=IMAGE_SIZE),\n",
    "        albumentations.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE, p=1.0),\n",
    "        # albumentations.CropNonEmptyMaskIfExists(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "        # albumentations.PadIfNeeded(min_height=IMAGE_SIZE, min_width=IMAGE_SIZE, p=1.0),\n",
    "        albumentations.ChannelShuffle(p=0.5),\n",
    "        albumentations.HorizontalFlip(p=0.5),\n",
    "        albumentations.AdvancedBlur(p=0.5),\n",
    "        # albumentations.GaussNoise(p=0.1, std_range=[0.01, 0.1]),\n",
    "        albumentations.CLAHE(p=0.5),\n",
    "        albumentations.RandomBrightnessContrast(p=0.5),\n",
    "        albumentations.RandomGamma(p=0.5),\n",
    "        albumentations.ColorJitter(p=0.5),\n",
    "        albumentations.Normalize(),  # !!!\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = albumentations.Compose(\n",
    "    [\n",
    "        # albumentations.SmallestMaxSize(max_size=IMAGE_SIZE),\n",
    "        albumentations.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE, p=1.0),\n",
    "        # albumentations.CropNonEmptyMaskIfExists(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "        albumentations.Normalize(),  # !!!\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88cc6ba-7bbf-403f-acca-b6b1e6978d45",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0f487b-abee-4652-b95b-cb1affbe6c34",
   "metadata": {},
   "source": [
    "Набор данных Pascal VOC. Рассмотрим его версию для задачи сегментации. \n",
    "\n",
    "Сайт: http://host.robots.ox.ac.uk/pascal/VOC/\n",
    "\n",
    "Лидерборд за 2012 год: http://host.robots.ox.ac.uk:8080/leaderboard/displaylb_main.php?challengeid=11&compid=5\n",
    "\n",
    "При тех или иных проблемах со скачиванием с сайта соревнования, скачайте и распакуйте архив в папку `data` (`data/VOCdevkit`) отсюда: https://disk.yandex.ru/d/1jS3yBBN7YdZ-w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88e21f6-543f-47a2-97ef-781a0a997449",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomVOCSegmentation(\n",
    "    root=\"data\",\n",
    "    year=\"2012\",\n",
    "    image_set=\"train\",\n",
    "    download=False,  # set to True druing first run\n",
    "    transform=train_transforms,  # transform, not transforms!\n",
    ")\n",
    "\n",
    "val_dataset = CustomVOCSegmentation(\n",
    "    root=\"data\",\n",
    "    year=\"2012\",\n",
    "    image_set=\"val\",\n",
    "    download=False,\n",
    "    transform=val_transforms,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f09949-7e66-43d9-824b-0595a09f3a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, target = train_dataset[0]\n",
    "Image.fromarray(image.numpy().astype(np.uint8).transpose(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35db8825-5df7-4383-b1e2-5668b1dcd685",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(255 * target[15, :, :].numpy().astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc77e07d-9b6c-4ee7-a4ac-bc37b6b77344",
   "metadata": {},
   "source": [
    "## UNet model\n",
    "\n",
    "Статья: https://arxiv.org/abs/1505.04597"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a84d99-23f3-45a7-8ecd-cafcaab21224",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(in_channels=3, out_channels=21)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77d6128-a241-4e0b-8cfa-9b8636b5f5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_pytorch_model_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b22de3-372a-48d9-ac36-95ac41dbee39",
   "metadata": {},
   "source": [
    "## Accelerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfe33d9-cce0-4373-ade0-6395cc8492a5",
   "metadata": {},
   "source": [
    "\"Accelerate — это библиотека, которая позволяет запускать один и тот же код PyTorch в любой распределенной конфигурации, добавляя всего четыре строки кода! Короче говоря, обучение и вывод в больших масштабах стали простыми, эффективными и адаптируемыми\". (c)\n",
    "\n",
    "Сайт: https://huggingface.co/docs/accelerate/index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ca43ec-8ee3-4f92-9537-dba305bd18f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator(cpu=False, mixed_precision=\"fp16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de663eed-5747-4e58-b263-43a2f8a73800",
   "metadata": {},
   "source": [
    "## Checkpointer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06471151-0ca3-46c0-a3a0-f33b53853a75",
   "metadata": {},
   "source": [
    "Класс для сохранения наилучших версий модели в процессе обучения.\n",
    "\n",
    "См. класс `Checkpointer` в `train.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658bce9e-3f9d-46ed-9950-1d0a66e5376f",
   "metadata": {},
   "source": [
    "## Обучаем модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6fbee0-3925-494e-ae3e-a469042dd5a4",
   "metadata": {},
   "source": [
    "См. `train.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b04b29f-46ff-45aa-9cba-5a6f03c72470",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES_NUM = 21\n",
    "\n",
    "BACKBONE_NAME = \"resnet50\"\n",
    "\n",
    "LEARNING_RATE = 1e-4\n",
    "WEIGHT_DECAY = 1e-5\n",
    "BETAS = (0.9, 0.999)\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 8\n",
    "EPOCH_NUM = 100\n",
    "SCHEDULER_STEP_SIZE = 50\n",
    "SCHEDULER_GAMMA = 0.1\n",
    "CHECKPOINTS_DIR = \"checkpoints\"\n",
    "TENSORBOARD_DIR = \"tensorboard\"\n",
    "RM_CHECKPOINTS_DIR = False\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24b17ad-99e7-4346-a5a4-38303c48221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(cpu=\"cpu\" == DEVICE, mixed_precision=\"fp16\")\n",
    "\n",
    "# model = UNet(in_channels=3, out_channels=CLASSES_NUM, bilinear=True)\n",
    "model = CustomUNet(backbone_name=BACKBONE_NAME, classes_num=CLASSES_NUM)\n",
    "# model = deeplabv3_resnet50()\n",
    "\n",
    "loss_fn = CrossEntropyLoss(ignore_index=255, reduction=\"sum\")\n",
    "metric_fn = IoUMetric(classes_num=CLASSES_NUM, reduction=\"macro\")\n",
    "metric_fns = {metric_fn.__class__.__name__: metric_fn}\n",
    "\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY, betas=BETAS\n",
    ")\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(\n",
    "    optimizer=optimizer, step_size=SCHEDULER_STEP_SIZE, gamma=SCHEDULER_GAMMA\n",
    ")\n",
    "\n",
    "os.makedirs(CHECKPOINTS_DIR, exist_ok=True)\n",
    "checkpointer = CheckpointSaver(\n",
    "    accelerator=accelerator,\n",
    "    model=model,\n",
    "    metric_name=metric_fn.__class__.__name__,\n",
    "    save_dir=CHECKPOINTS_DIR,\n",
    "    rm_save_dir=RM_CHECKPOINTS_DIR,\n",
    "    max_history=5,\n",
    "    should_minimize=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c16bbd-6ca0-4663-ab75-ea46492447b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(TENSORBOARD_DIR, exist_ok=True)\n",
    "tensorboard_logger = torch.utils.tensorboard.SummaryWriter(log_dir=TENSORBOARD_DIR)\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"tensorboard\"  --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d830ff9-3e9e-4f0b-995c-128060eee0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# акселерируем\n",
    "model, optimizer, train_dataloader, val_dataloader, lr_scheduler = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, val_dataloader, lr_scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1cea82-a47b-4b74-a0e5-22de5bd3c9f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    metric_fns=metric_fns,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    accelerator=accelerator,\n",
    "    epoch_num=EPOCH_NUM,\n",
    "    checkpointer=checkpointer,\n",
    "    tb_logger=tensorboard_logger,\n",
    "    save_on_val=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fab484-d2b8-40db-a141-4d7c4eaeb8e8",
   "metadata": {},
   "source": [
    "## Загрузим и протестируем обученную модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8beaea3-83c6-4f8f-a3f4-392898f18ee4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = UNet(in_channels=3, out_channels=CLASSES_NUM)\n",
    "model = CustomUNet(backbone_name=BACKBONE_NAME, classes_num=CLASSES_NUM)\n",
    "# model = deeplabv3_resnet50()\n",
    "model = load_checkpoint(\n",
    "    model=model,\n",
    "    load_path=pjoin(CHECKPOINTS_DIR, \"model_checkpoint_best.pt\"),\n",
    ")  # \"custom_unet\" \"deeplabv3plus\"\n",
    "model = model.to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64c5c6b-7631-4816-93cb-8156f055810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 0\n",
    "image, target = val_dataset[sample_idx]\n",
    "target = torch.argmax(target, axis=0)\n",
    "preds = torch.argmax(\n",
    "    F.softmax(model(image.unsqueeze(0).to(DEVICE)), dim=1).squeeze(0), axis=0\n",
    ")\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(9, 18))\n",
    "ax[0].imshow(image.numpy().transpose(1, 2, 0).astype(np.uint8))\n",
    "ax[1].imshow(target.numpy())\n",
    "ax[2].imshow(preds.cpu().numpy());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc82364-40d1-4a15-9639-918fa016267f",
   "metadata": {},
   "source": [
    "## Разметка данных с помощью CVAT\n",
    "\n",
    "Сайт: https://www.cvat.ai/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0078539-e63a-453e-9e9e-a29e1fec4dcb",
   "metadata": {},
   "source": [
    "## Обзоры бекбонов\n",
    "\n",
    "- Обзор до ~2020: https://arxiv.org/pdf/2206.08016.pdf\n",
    "- Чуть поновее: https://arxiv.org/pdf/2310.19909.pdf\n",
    "- Трансформеры и VLM как-нибудь потом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2687d96d-94b2-4416-ac20-872bd48e9edf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
