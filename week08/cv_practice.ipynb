{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cffdd5d6-3712-45d2-b5c0-cbb48b5f377d",
   "metadata": {},
   "source": [
    "# Обучение моделей в Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc18f6a-31c9-4ff1-b7a7-02a7a13f85cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from os.path import join as pjoin\n",
    "from shutil import rmtree\n",
    "\n",
    "import albumentations\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from accelerate import Accelerator\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision import datasets\n",
    "\n",
    "from checkpointer import CheckpointSaver, load_checkpoint\n",
    "from dataset import CLASS_WEIGHTS, CustomVOCSegmentation, convert_label_to_color\n",
    "from deeplabv3plus.modeling import deeplabv3plus_resnet50\n",
    "from loss import CrossEntropyDiceLoss\n",
    "from metric import MeanIoU\n",
    "from train import count_pytorch_model_params, train\n",
    "from unet import UNet\n",
    "from unet_custom import CustomUNet\n",
    "from utils import seed_everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12069a41-bbcb-4292-931b-27c367515ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything(42, torch_deterministic=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d17238-f92d-4347-a84e-91b2f37598bc",
   "metadata": {},
   "source": [
    "## Аугментации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0959cf2-ad28-4ae5-84f9-02fd7beb6190",
   "metadata": {},
   "source": [
    "Трансформации/аугментации для исходных изображений и масок/таргетов.\n",
    "\n",
    "Аугментации для задач компьютерного хрения: https://albumentations.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662c1e5a-ca36-4b9f-802a-da8e3786c5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 256\n",
    "MEAN = np.array([0.485, 0.456, 0.406])\n",
    "STD = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "train_transforms = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.SmallestMaxSize(max_size=IMAGE_SIZE),\n",
    "        albumentations.CropNonEmptyMaskIfExists(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "        # albumentations.Resize(IMAGE_SIZE, IMAGE_SIZE),\n",
    "        albumentations.HorizontalFlip(p=0.5),\n",
    "        albumentations.ShiftScaleRotate(\n",
    "            shift_limit=0.05,\n",
    "            scale_limit=0.1,\n",
    "            rotate_limit=15,\n",
    "            p=0.5,\n",
    "        ),\n",
    "        albumentations.RandomCrop(IMAGE_SIZE, IMAGE_SIZE, p=1.0),\n",
    "        albumentations.OneOf(\n",
    "            [\n",
    "                albumentations.CLAHE(p=0.3),\n",
    "                albumentations.RandomBrightnessContrast(p=0.5),\n",
    "                albumentations.HueSaturationValue(p=0.3),\n",
    "            ],\n",
    "            p=0.8,\n",
    "        ),\n",
    "        albumentations.Normalize(mean=MEAN, std=STD),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")\n",
    "\n",
    "val_transforms = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE, p=1.0),\n",
    "        albumentations.Normalize(mean=MEAN, std=STD),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88cc6ba-7bbf-403f-acca-b6b1e6978d45",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0f487b-abee-4652-b95b-cb1affbe6c34",
   "metadata": {},
   "source": [
    "Набор данных Pascal VOC. Рассмотрим его версию для задачи сегментации. \n",
    "\n",
    "Сайт: http://host.robots.ox.ac.uk/pascal/VOC/\n",
    "\n",
    "Лидерборд за 2012 год: http://host.robots.ox.ac.uk:8080/leaderboard/displaylb_main.php?challengeid=11&compid=5\n",
    "\n",
    "При тех или иных проблемах со скачиванием с сайта соревнования, скачайте и распакуйте архив в папку `data` (`data/VOCdevkit`) отсюда: https://disk.yandex.ru/d/1jS3yBBN7YdZ-w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88e21f6-543f-47a2-97ef-781a0a997449",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomVOCSegmentation(\n",
    "    root=\"data\",\n",
    "    year=\"2012\",\n",
    "    image_set=\"train\",\n",
    "    download=False,  # True\n",
    "    transform=train_transforms,  # transform, not transforms!\n",
    ")\n",
    "\n",
    "val_dataset = CustomVOCSegmentation(\n",
    "    root=\"data\",\n",
    "    year=\"2012\",\n",
    "    image_set=\"val\",\n",
    "    download=False,\n",
    "    transform=val_transforms,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f09949-7e66-43d9-824b-0595a09f3a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, target = train_dataset[0]\n",
    "\n",
    "image_orig = image * STD[:, None, None] + MEAN[:, None, None]\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(9, 18))\n",
    "ax[0].imshow(image_orig.numpy().transpose(1, 2, 0) + 1e-5)\n",
    "ax[1].imshow(image.numpy().transpose(1, 2, 0))\n",
    "ax[2].imshow(convert_label_to_color(target.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc77e07d-9b6c-4ee7-a4ac-bc37b6b77344",
   "metadata": {},
   "source": [
    "## UNet model\n",
    "\n",
    "Статья: https://arxiv.org/abs/1505.04597"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a84d99-23f3-45a7-8ecd-cafcaab21224",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(in_channels=3, out_channels=21)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77d6128-a241-4e0b-8cfa-9b8636b5f5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_pytorch_model_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b22de3-372a-48d9-ac36-95ac41dbee39",
   "metadata": {},
   "source": [
    "## Accelerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfe33d9-cce0-4373-ade0-6395cc8492a5",
   "metadata": {},
   "source": [
    "\"Accelerate — это библиотека, которая позволяет запускать один и тот же код PyTorch в любой распределенной конфигурации, добавляя всего четыре строки кода! Короче говоря, обучение и вывод в больших масштабах стали простыми, эффективными и адаптируемыми\". (c)\n",
    "\n",
    "Сайт: https://huggingface.co/docs/accelerate/index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ca43ec-8ee3-4f92-9537-dba305bd18f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accelerator = Accelerator(cpu=False, mixed_precision=\"no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de663eed-5747-4e58-b263-43a2f8a73800",
   "metadata": {},
   "source": [
    "## Checkpointer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06471151-0ca3-46c0-a3a0-f33b53853a75",
   "metadata": {},
   "source": [
    "Класс для сохранения наилучших версий модели в процессе обучения.\n",
    "\n",
    "См. класс `Checkpointer` в `train.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658bce9e-3f9d-46ed-9950-1d0a66e5376f",
   "metadata": {},
   "source": [
    "## Обучаем модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6fbee0-3925-494e-ae3e-a469042dd5a4",
   "metadata": {},
   "source": [
    "См. `train.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b04b29f-46ff-45aa-9cba-5a6f03c72470",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES_NUM = 21\n",
    "\n",
    "BACKBONE_NAME = \"resnet50\"\n",
    "\n",
    "LEARNING_RATE_SGD = 1e-3\n",
    "LEARNING_RATE_ADAM = 1e-4\n",
    "MIN_LEARNING_RATE = 1e-6\n",
    "WEIGHT_DECAY = 1e-4\n",
    "MOMENTUM_SGD = 0.9\n",
    "BETAS_ADAM = (0.9, 0.999)\n",
    "BATCH_SIZE = 16\n",
    "NUM_WORKERS = 4\n",
    "EPOCH_NUM = 100\n",
    "SCHEDULER_PATIENCE = 5\n",
    "SCHEDULER_GAMMA = 0.5\n",
    "CHECKPOINTS_DIR = \"checkpoints\"\n",
    "TENSORBOARD_DIR = \"tensorboard\"\n",
    "RM_CHECKPOINTS_DIR = False\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24b17ad-99e7-4346-a5a4-38303c48221d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=True,\n",
    "    drop_last=True,\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "accelerator = Accelerator(cpu=\"cpu\" == DEVICE, mixed_precision=\"no\")\n",
    "\n",
    "# model = UNet(in_channels=3, out_channels=CLASSES_NUM, bilinear=True)\n",
    "model = CustomUNet(backbone_name=BACKBONE_NAME, classes_num=CLASSES_NUM)\n",
    "# model = deeplabv3plus_resnet50()\n",
    "\n",
    "model = load_checkpoint(\n",
    "    model=model,\n",
    "    load_path=pjoin(CHECKPOINTS_DIR, \"model_checkpoint_best.pt\"),\n",
    ")\n",
    "\n",
    "class_weights = torch.tensor(CLASS_WEIGHTS).to(DEVICE)\n",
    "# loss_fn = nn.CrossEntropyLoss(weight=class_weights, reduction=\"mean\", ignore_index=255)\n",
    "loss_fn = CrossEntropyDiceLoss(weight=class_weights, ignore_index=255)\n",
    "\n",
    "metric_fn = MeanIoU(classes_num=CLASSES_NUM, ignore_index=255).to(DEVICE)\n",
    "metric_fns = {metric_fn.__class__.__name__: metric_fn}\n",
    "\n",
    "optimizer = torch.optim.SGD(\n",
    "    model.parameters(),\n",
    "    lr=LEARNING_RATE_SGD,\n",
    "    weight_decay=WEIGHT_DECAY,\n",
    "    nesterov=True,\n",
    "    momentum=MOMENTUM_SGD,\n",
    ")\n",
    "# optimizer = torch.optim.AdamW(\n",
    "#     model.parameters(), lr=LEARNING_RATE_ADAM, weight_decay=WEIGHT_DECAY, betas=BETAS_ADAM\n",
    "# )\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer=optimizer,\n",
    "    mode=\"max\",\n",
    "    factor=SCHEDULER_GAMMA,\n",
    "    patience=SCHEDULER_PATIENCE,\n",
    "    min_lr=MIN_LEARNING_RATE,\n",
    ")\n",
    "\n",
    "os.makedirs(CHECKPOINTS_DIR, exist_ok=True)\n",
    "checkpointer = CheckpointSaver(\n",
    "    accelerator=accelerator,\n",
    "    model=model,\n",
    "    metric_name=metric_fn.__class__.__name__,\n",
    "    save_dir=CHECKPOINTS_DIR,\n",
    "    rm_save_dir=RM_CHECKPOINTS_DIR,\n",
    "    max_history=5,\n",
    "    should_minimize=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c16bbd-6ca0-4663-ab75-ea46492447b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(TENSORBOARD_DIR, exist_ok=True)\n",
    "tensorboard_logger = torch.utils.tensorboard.SummaryWriter(log_dir=TENSORBOARD_DIR)\n",
    "\n",
    "# Раскомментировать в Google Colab\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir \"tensorboard\"  --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d830ff9-3e9e-4f0b-995c-128060eee0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer, train_dataloader, val_dataloader, lr_scheduler = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, val_dataloader, lr_scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1cea82-a47b-4b74-a0e5-22de5bd3c9f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    metric_fns=metric_fns,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    accelerator=accelerator,\n",
    "    epoch_num=EPOCH_NUM,\n",
    "    checkpointer=checkpointer,\n",
    "    tb_logger=tensorboard_logger,\n",
    "    save_on_val=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fab484-d2b8-40db-a141-4d7c4eaeb8e8",
   "metadata": {},
   "source": [
    "## Загрузим и протестируем обученную модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8beaea3-83c6-4f8f-a3f4-392898f18ee4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "CHECKPOINTS_DIR = \"checkpoints\"\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# model = UNet(in_channels=3, out_channels=CLASSES_NUM)\n",
    "model = CustomUNet(backbone_name=BACKBONE_NAME, classes_num=CLASSES_NUM)\n",
    "# model = deeplabv3plus_resnet50()\n",
    "\n",
    "model = load_checkpoint(\n",
    "    model=model,\n",
    "    load_path=pjoin(CHECKPOINTS_DIR, \"model_checkpoint_best.pt\"),\n",
    ")\n",
    "model = model.to(DEVICE)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64c5c6b-7631-4816-93cb-8156f055810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 10\n",
    "image, target = val_dataset[sample_idx]\n",
    "\n",
    "preds = torch.argmax(model(image.unsqueeze(0).to(DEVICE)).squeeze(0), axis=0)\n",
    "\n",
    "image = image * STD[:, None, None] + MEAN[:, None, None]\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(9, 18))\n",
    "ax[0].imshow(image.numpy().transpose(1, 2, 0))\n",
    "ax[1].imshow(convert_label_to_color(target.numpy()))\n",
    "ax[2].imshow(convert_label_to_color(preds.cpu().numpy()));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc82364-40d1-4a15-9639-918fa016267f",
   "metadata": {},
   "source": [
    "## Разметка данных с помощью CVAT\n",
    "\n",
    "Сайт: https://www.cvat.ai/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0078539-e63a-453e-9e9e-a29e1fec4dcb",
   "metadata": {},
   "source": [
    "## Обзоры бекбонов\n",
    "\n",
    "- Обзор до ~2020: https://arxiv.org/pdf/2206.08016.pdf\n",
    "- Чуть поновее: https://arxiv.org/pdf/2310.19909.pdf\n",
    "- Трансформеры и VLM как-нибудь потом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2687d96d-94b2-4416-ac20-872bd48e9edf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
