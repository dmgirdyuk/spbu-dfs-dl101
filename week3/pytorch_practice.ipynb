{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cffdd5d6-3712-45d2-b5c0-cbb48b5f377d",
   "metadata": {},
   "source": [
    "# Обучение моделей в Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fc18f6a-31c9-4ff1-b7a7-02a7a13f85cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join as pjoin\n",
    "from shutil import rmtree\n",
    "\n",
    "import albumentations\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from accelerate import Accelerator\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from dataset import CustomVOCSegmentation\n",
    "from train import CheckpointSaver, load_checkpoint, train\n",
    "from unet import UNet, count_model_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d17238-f92d-4347-a84e-91b2f37598bc",
   "metadata": {},
   "source": [
    "## Агументации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0959cf2-ad28-4ae5-84f9-02fd7beb6190",
   "metadata": {},
   "source": [
    "Трансформации/аугментации для исходных изображений и масок/таргетов.\n",
    "\n",
    "Аугментации для задач компьютерного хрения: https://albumentations.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "662c1e5a-ca36-4b9f-802a-da8e3786c5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 512\n",
    "transforms = albumentations.Compose(\n",
    "    [\n",
    "        albumentations.Resize(height=IMAGE_SIZE, width=IMAGE_SIZE),\n",
    "        albumentations.AdvancedBlur(p=0.5),\n",
    "        albumentations.GaussNoise(p=0.5),\n",
    "        albumentations.HorizontalFlip(p=0.5),\n",
    "        albumentations.CLAHE(p=0.5),\n",
    "        albumentations.RandomBrightnessContrast(p=0.5),\n",
    "        albumentations.RandomGamma(p=0.5),\n",
    "        albumentations.ColorJitter(p=0.5),\n",
    "        ToTensorV2(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88cc6ba-7bbf-403f-acca-b6b1e6978d45",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0f487b-abee-4652-b95b-cb1affbe6c34",
   "metadata": {},
   "source": [
    "Набор данных Pascal VOC. Рассмотрим его версию для задачи сегментации. \n",
    "\n",
    "Сайт: http://host.robots.ox.ac.uk/pascal/VOC/\n",
    "\n",
    "Лидерборд за 2012 год: http://host.robots.ox.ac.uk:8080/leaderboard/displaylb_main.php?challengeid=11&compid=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f057bd-99cc-4053-86a5-af4feaa556be",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.VOCSegmentation(\n",
    "    root=\"data\",\n",
    "    year=\"2012\",\n",
    "    image_set=\"train\",\n",
    "    download=True,\n",
    "    transforms=transforms,\n",
    ")\n",
    "\n",
    "val_dataset = datasets.VOCSegmentation(\n",
    "    root=\"data\",\n",
    "    year=\"2012\",\n",
    "    image_set=\"val\",\n",
    "    download=True,\n",
    "    transforms=transforms,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0042fcbf-a4fb-4ebe-a14c-74934848e897",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87df0ac5-850f-4372-8d2a-31c8f6988e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, target = train_dataset[0]\n",
    "Image.fromarray(image.numpy().transpose(1, 2, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc834f45-2aa4-49cb-952d-46da0dc2ad73",
   "metadata": {},
   "source": [
    "Проблема!\n",
    "\n",
    "См. `dataset.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a88e21f6-543f-47a2-97ef-781a0a997449",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomVOCSegmentation(\n",
    "    root=\"data\",\n",
    "    year=\"2012\",\n",
    "    image_set=\"train\",\n",
    "    download=False,\n",
    "    transform=transforms,  # transform!\n",
    ")\n",
    "\n",
    "val_dataset = CustomVOCSegmentation(\n",
    "    root=\"data\",\n",
    "    year=\"2012\",\n",
    "    image_set=\"val\",\n",
    "    download=False,\n",
    "    transform=transforms,  # transform!\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f09949-7e66-43d9-824b-0595a09f3a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, target = train_dataset[0]\n",
    "Image.fromarray(image.numpy().astype(np.uint8).transpose(1, 2, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35db8825-5df7-4383-b1e2-5668b1dcd685",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image.fromarray(255 * target[15, :, :].numpy().astype(np.uint8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc77e07d-9b6c-4ee7-a4ac-bc37b6b77344",
   "metadata": {},
   "source": [
    "## UNet model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70db12b0-0673-454c-9c7d-ea1ed4f88e37",
   "metadata": {},
   "source": [
    "![UNet](unet.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b96c8104-7147-4dd7-99e9-ddf4663cf57b",
   "metadata": {},
   "source": [
    "Визуализация разных типов сверток: https://github.com/vdumoulin/conv_arithmetic/blob/master/README.md\n",
    "\n",
    "См. `unet.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a84d99-23f3-45a7-8ecd-cafcaab21224",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(in_channels=3, out_channels=21)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77d6128-a241-4e0b-8cfa-9b8636b5f5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_model_params(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b22de3-372a-48d9-ac36-95ac41dbee39",
   "metadata": {},
   "source": [
    "## Accelerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfe33d9-cce0-4373-ade0-6395cc8492a5",
   "metadata": {},
   "source": [
    "\"Accelerate — это библиотека, которая позволяет запускать один и тот же код PyTorch в любой распределенной конфигурации, добавляя всего четыре строки кода! Короче говоря, обучение и вывод в больших масштабах стали простыми, эффективными и адаптируемыми\". (c)\n",
    "\n",
    "Сайт: https://huggingface.co/docs/accelerate/index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ca43ec-8ee3-4f92-9537-dba305bd18f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "accelerator = Accelerator(cpu=False, mixed_precision=\"fp16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de663eed-5747-4e58-b263-43a2f8a73800",
   "metadata": {},
   "source": [
    "## Checkpointer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06471151-0ca3-46c0-a3a0-f33b53853a75",
   "metadata": {},
   "source": [
    "Класс для сохранения наилучших версий модели в процессе обучения.\n",
    "\n",
    "См. класс `Checkpointer` в `train.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658bce9e-3f9d-46ed-9950-1d0a66e5376f",
   "metadata": {},
   "source": [
    "## Обучаем модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6fbee0-3925-494e-ae3e-a469042dd5a4",
   "metadata": {},
   "source": [
    "См. `train.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b04b29f-46ff-45aa-9cba-5a6f03c72470",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-4\n",
    "BATCH_SIZE = 4\n",
    "NUM_WORKERS = 2\n",
    "EPOCH_NUM = 1\n",
    "CHECKPOINTS_DIR = \"checkpoints\"\n",
    "TENSORBOARD_DIR = \"tensorboard\"\n",
    "RM_CHECKPOINTS_DIR = False\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24b17ad-99e7-4346-a5a4-38303c48221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True\n",
    ")\n",
    "val_dataloader = DataLoader(\n",
    "    val_dataset, batch_size=BATCH_SIZE, num_workers=NUM_WORKERS, shuffle=True\n",
    ")\n",
    "\n",
    "model = UNet(in_channels=3, out_channels=21)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LEARNING_RATE)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer=optimizer, step_size=5, gamma=0.8)\n",
    "metric_fn = loss_fn\n",
    "\n",
    "if RM_CHECKPOINTS_DIR:\n",
    "    rmtree(CHECKPOINTS_DIR, ignore_errors=True)\n",
    "\n",
    "os.makedirs(CHECKPOINTS_DIR, exist_ok=True)\n",
    "checkpointer = CheckpointSaver(\n",
    "    accelerator=accelerator,\n",
    "    model=model,\n",
    "    metric_name=\"metric\",\n",
    "    save_dir=CHECKPOINTS_DIR,\n",
    "    max_history=5,\n",
    "    should_minimize=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c16bbd-6ca0-4663-ab75-ea46492447b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorboard\n",
    "# tensorboard_logger = None\n",
    "\n",
    "os.makedirs(TENSORBOARD_DIR, exist_ok=True)\n",
    "tensorboard_logger = torch.utils.tensorboard.SummaryWriter(log_dir=TENSORBOARD_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d830ff9-3e9e-4f0b-995c-128060eee0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# акселерируем\n",
    "model, optimizer, train_dataloader, val_dataloader, lr_scheduler = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, val_dataloader, lr_scheduler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1cea82-a47b-4b74-a0e5-22de5bd3c9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\n",
    "    model=model,\n",
    "    optimizer=optimizer,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    loss_function=loss_fn,\n",
    "    metric_function=metric_fn,\n",
    "    lr_scheduler=lr_scheduler,\n",
    "    accelerator=accelerator,\n",
    "    epoch_num=EPOCH_NUM,\n",
    "    checkpointer=checkpointer,\n",
    "    tb_logger=tensorboard_logger,\n",
    "    save_on_val=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fab484-d2b8-40db-a141-4d7c4eaeb8e8",
   "metadata": {},
   "source": [
    "## Загрузим и протестируем обученную модель"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e525873-0ec6-45af-9792-ddad215381db",
   "metadata": {},
   "source": [
    "Предобученный чекпоинт: https://disk.yandex.ru/d/C6dRX7Un1L7qsw\n",
    "\n",
    "Поместить в \".\\checkpoints\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8beaea3-83c6-4f8f-a3f4-392898f18ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(in_channels=3, out_channels=21)\n",
    "model = load_checkpoint(model=model, load_path=pjoin(CHECKPOINTS_DIR, \"model_checkpoint_best.pt\"))\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64c5c6b-7631-4816-93cb-8156f055810c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_idx = 42\n",
    "image, target = val_dataset[sample_idx]\n",
    "target = torch.argmax(target, axis=0)\n",
    "preds = torch.argmax(F.softmax(model(image.unsqueeze(0).to(DEVICE)), dim=1).squeeze(0), axis=0)\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(9, 18));\n",
    "ax[0].imshow(image.numpy().transpose(1, 2, 0).astype(np.uint8));\n",
    "ax[1].imshow(target.numpy());\n",
    "ax[2].imshow(preds.cpu().numpy());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10a1eb7e-cd5f-4f5e-85ad-1586cc2fffb4",
   "metadata": {},
   "source": [
    "## Вопросы/задание на оставшееся время"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67fd122-d63d-466b-a9fe-1309501f1c76",
   "metadata": {},
   "source": [
    "- Каким образом можно сделать так, чтобы модель предсказывала лишь бинарную маску, на которой отмечены люди?\n",
    "- Что нам нужно сделать, чтобы дообучить эту модель предсказывать только людей на том же самом датасете?\n",
    "- Реализуйте самостоятельно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890f047a-20ad-4b06-a409-d8f7da5a2e8d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
